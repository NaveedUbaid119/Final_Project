{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "da=pd.read_csv(r'/Users/IAmNaveed/Desktop/Bank_Marketing/Data/small_ohe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Outcome and Input Variables\n",
    "X = da.drop('y', axis=1).values\n",
    "y = da['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Train and Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.1], 'C': [1]},\n",
    "                    {'kernel': ['linear'], 'C': [1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.1], 'C': [1]}, {'kernel': ['linear'], 'C': [1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='precision')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Selected is:  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'} Which Produces a precision of  0.8302833451252198\n"
     ]
    }
   ],
   "source": [
    "print('Model Selected is: ', clf.best_params_ ,'Which Produces a precision of ', clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision on the evaluation set:  0.8480603448275862\n",
      "recall on the evaluation set:  0.7266851338873499\n",
      "accuracy on the evaluation set:  0.7998167659184608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "pre1 = precision_score(y_true, y_pred)\n",
    "rec1 = recall_score(y_true, y_pred)\n",
    "acc1 = accuracy_score(y_true, y_pred)\n",
    "f1_1 = f1_score(y_true, y_pred)\n",
    "print('precision on the evaluation set: ', pre1)\n",
    "print('recall on the evaluation set: ', rec1)\n",
    "print('accuracy on the evaluation set: ', acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7276, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# raw data\n",
    "X = da.drop('y', axis=1).values\n",
    "y = da['y'].values\n",
    "# split, random_state is used for repeatable results, you should remove it if you are running your own code.\n",
    "pca = PCA(n_components=0.9)\n",
    "x_pca = pca.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.30, random_state=42)\n",
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.1],\n",
    "                     'C': [1]},\n",
    "                    {'kernel': ['linear'], 'C': [1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.1], 'C': [1]}, {'kernel': ['linear'], 'C': [1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='precision')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Selected is:  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'} Which Produces a precision of  0.7998243179740869\n"
     ]
    }
   ],
   "source": [
    "print('Model Selected is: ', clf.best_params_ ,'Which Produces a precision of ', clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision on the evaluation set:  0.8419889502762431\n",
      "recall on the evaluation set:  0.703601108033241\n",
      "accuracy on the evaluation set:  0.7874484654145671\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "pre2 = precision_score(y_true, y_pred)\n",
    "rec2 = recall_score(y_true, y_pred)\n",
    "acc2 = accuracy_score(y_true, y_pred)\n",
    "f1_2 = f1_score(y_true, y_pred)\n",
    "print('precision on the evaluation set: ', pre2)\n",
    "print('recall on the evaluation set: ', rec2)\n",
    "print('accuracy on the evaluation set: ', acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score Without PCA</th>\n",
       "      <th>Score With PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.799817</td>\n",
       "      <td>0.787448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.848060</td>\n",
       "      <td>0.841989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.726685</td>\n",
       "      <td>0.703601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.782695</td>\n",
       "      <td>0.766600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric  Score Without PCA  Score With PCA\n",
       "0   Accuracy           0.799817        0.787448\n",
       "1  Precision           0.848060        0.841989\n",
       "2     Recall           0.726685        0.703601\n",
       "3   F1 Score           0.782695        0.766600"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score Without PCA': [acc1, pre1, rec1, f1_1],\n",
    "    'Score With PCA': [acc2, pre2, rec2, f1_2]\n",
    "    })\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
